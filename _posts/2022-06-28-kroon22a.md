---
abstract: The Causal Bandit is a variant of the classic Bandit problem where an agent
  must identify the best action in a sequential decision-making process, where the
  reward distribution of the actions displays a non-trivial dependence structure that
  is governed by a causal model. All methods proposed for this problem thus far in
  the literature rely on exact prior knowledge of the full causal. We formulate new
  causal bandit algorithms that no longer necessarily rely on prior causal knowledge.
  Instead, they utilize an estimator based on separating sets, which we can find using
  simple conditional independence tests or causal discovery methods. We show that,
  for discrete i.i.d. data, this estimator is unbiased, and has variance which is
  upper bounded by that of the sample mean. We develop algorithms based on Thompson
  Sampling and UCB for discrete and Gaussian models respectively and show increased
  performance on simulation data as well as on a bandit drawing from real-world protein
  signaling data.
booktitle: First Conference on Causal Learning and Reasoning
title: Causal Bandits without prior knowledge using separating sets
year: '2022'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kroon22a
month: 0
tex_title: Causal Bandits without prior knowledge using separating sets
firstpage: 407
lastpage: 427
page: 407-427
order: 407
cycles: false
bibtex_author: Kroon, Arnoud De and Mooij, Joris and Belgrave, Danielle
author:
- given: Arnoud De
  family: Kroon
- given: Joris
  family: Mooij
- given: Danielle
  family: Belgrave
date: 2022-06-28
address:
container-title: Proceedings of the First Conference on Causal Learning and Reasoning
volume: '177'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v177/kroon22a/kroon22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
